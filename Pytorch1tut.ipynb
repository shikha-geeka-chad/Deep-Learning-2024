{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIH0K9s1cTSKH0Rf2Y0m/6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shikha-geeka-chad/Deep-Learning-2024/blob/main/Pytorch1tut.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Wu6rlXsTYNcn"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2)\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gHcofGAYTgZ",
        "outputId": "670249a9-a191-42fd-ab94-ec7e091f85b5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.8834, 0.2543])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1)\n",
        "y = torch.tensor(2)\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "y_hat= w*x\n",
        "loss =( y_hat - y)**2\n",
        "print(loss)\n",
        "\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMXA9-SRZCuT",
        "outputId": "a87378e8-8277-4e1f-f83a-9055cf7c4d3d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ff5fe36"
      },
      "source": [
        "Now that we have the gradients, we can perform a simple gradient descent step to update the weights. We'll use a learning rate to control the size of the update."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "970371a9",
        "outputId": "d68d5e5b-cbca-48a5-a3cf-eee2e5c5c1be"
      },
      "source": [
        "# Define a learning rate\n",
        "learning_rate = 0.01\n",
        "\n",
        "# Update weights using gradient descent\n",
        "# We use with torch.no_grad() because we don't want to track gradients for this update step\n",
        "with torch.no_grad():\n",
        "    w1 -= learning_rate * w1.grad\n",
        "    w2 -= learning_rate * w2.grad\n",
        "\n",
        "# Manually zero the gradients after updating weights\n",
        "w1.grad.zero_()\n",
        "w2.grad.zero_()\n",
        "\n",
        "print(\"Updated w1:\", w1)\n",
        "print(\"Updated w2:\", w2)\n",
        "\n",
        "# Recalculate loss with updated weights\n",
        "y_hat = w1 * x1 + w2 * x2\n",
        "loss = torch.mean((y_hat - y)**2)\n",
        "print(\"New Loss:\", loss)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated w1: tensor(1.4200, requires_grad=True)\n",
            "Updated w2: tensor(1.4200, requires_grad=True)\n",
            "New Loss: tensor(22.8704, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7352906",
        "outputId": "f0d06045-e83b-4b52-f4d4-c2d952687139"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Assuming x1 and x2 have 5 data points each\n",
        "x1 = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float32)\n",
        "x2 = torch.tensor([5, 4, 3, 2, 1], dtype=torch.float32)\n",
        "y = torch.tensor([11, 14, 15, 14, 11], dtype=torch.float32) # Example target values\n",
        "\n",
        "w1 = torch.tensor(1.0, requires_grad=True)\n",
        "w2 = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# Linear model: y_hat = w1 * x1 + w2 * x2\n",
        "y_hat = w1 * x1 + w2 * x2\n",
        "\n",
        "# Mean squared error loss\n",
        "loss = torch.mean((y_hat - y)**2)\n",
        "print(\"Loss:\", loss)\n",
        "\n",
        "# Calculate gradients\n",
        "loss.backward()\n",
        "print(\"Gradient of w1:\", w1.grad)\n",
        "print(\"Gradient of w2:\", w2.grad)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: tensor(51.8000, grad_fn=<MeanBackward0>)\n",
            "Gradient of w1: tensor(-42.)\n",
            "Gradient of w2: tensor(-42.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dCKc-iI2hDmz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}